{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c1b830f-db15-43f5-82a8-d3228a6abb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import json\n",
    "from IPython.display import display, Markdown, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232cdafb-68c0-41ac-aa3d-4102d7478f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the API keys\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89887d6a-a859-4d15-ad0f-b8554cc55f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic System Message\n",
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0fd7aa3-8c3e-474e-ae7e-9e299dd8b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate openai object\n",
    "openai = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cb1a3ba-1aa4-4f25-b134-816c4753ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's wrap a call to GPT-4o-mini is a simple function\n",
    "def message_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    completion = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed7eb247-92f2-4a53-b6d5-289a09be226d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Today's date is October 8, 2023.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the function\n",
    "# This can reveal the \"training cut off\", or the most recent date in the training data\n",
    "message_gpt(\"What is today's Date?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd43d92-a020-4468-bf2e-3ac104717db7",
   "metadata": {},
   "source": [
    "### Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "043926e7-f85a-445f-b160-62ca6a2800ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple testing function\n",
    "def shout(text):\n",
    "    print(f\"Shout has been called with input: {text}\")\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0c8ff42-347b-452f-8751-1fda62b750f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with input: Hi\n",
      "Shout has been called with input: The test message\n"
     ]
    }
   ],
   "source": [
    "# Simple gradio interface\n",
    "gr.Interface(fn=shout, inputs='textbox', outputs='textbox').launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f2fdb57-a974-4979-b6e1-4d34037ee372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://88179681be246173ac.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://88179681be246173ac.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with input: Hi\n",
      "Shout has been called with input: Test message\n"
     ]
    }
   ],
   "source": [
    "# Adding share=True means that it can be accessed publically\n",
    "# A more permanent hosting is available using a platform called Spaces from HuggingFace,\n",
    "# NOTE: Some Anti-virus software and Corporate Firewalls might not like you using share=True. If you're at work on on a work network, I suggest skip this test.\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e754ed-c46d-46b6-b418-a45f12897c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with input: Hi\n",
      "Shout has been called with input: Hi\n",
      "Shout has been called with input: Test Message\n"
     ]
    }
   ],
   "source": [
    "# Adding inbrowser=True opens up a new browser window automatically\n",
    "gr.Interface(fn=shout, inputs='textbox', outputs='textbox', flagging_mode='never').launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d3708-5409-46b0-a150-78a292d00f7b",
   "metadata": {},
   "source": [
    "## Forcing dark mode\n",
    "\n",
    "Gradio appears in light mode or dark mode depending on the settings of the browser and computer. There is a way to force gradio to appear in dark mode, but Gradio recommends against this as it should be a user preference (particularly for accessibility reasons). But if you wish to force dark mode for your screens, below is how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e4a7a59-424e-43ae-9db4-2bfa0845551b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define this variable and then pass js=force_dark_mode when creating the Interface\n",
    "\n",
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\", js=force_dark_mode).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bee07bf-ecd1-45ae-95fe-527f36e360fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with input: Hi There!\n",
      "Shout has been called with input: Hi There!\n",
      "This is test message\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input and Output\n",
    "view = gr.Interface(\n",
    "    fn=shout, \n",
    "    inputs=[gr.Textbox(label='Your Message:', lines=6)],\n",
    "    outputs=[gr.Textbox(label='Response', lines=6)],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1632d380-96c3-415c-988b-9d760ee1a54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the function from 'shout' to 'message_gpt'\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    inputs=[gr.Textbox(label='Your Message:', lines=6)],\n",
    "    outputs=[gr.Textbox(label='Response:', lines=6)],\n",
    "    flagging_mode='never'\n",
    ")\n",
    "\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c30ce7c5-99d3-479e-8cb6-674d078dcf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use Markdown\n",
    "# Are you wondering why it makes any difference to set system_message when it's not referred to in the code below it?\n",
    "# I'm taking advantage of system_message being a global variable, used back in the message_gpt function (go take a look)\n",
    "# Not a great software engineering practice, but quite common during Jupyter Lab R&D!\n",
    "\n",
    "system_message = \"You are a helpful assistant that respond in markdown\"\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    inputs=[gr.Textbox(label='Your Message:')],\n",
    "    outputs=[gr.Markdown(label='Response:')],\n",
    "    flagging_mode='never'\n",
    ")\n",
    "\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3402aefa-b8a5-4da7-b30b-9506bf88cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a call that streams back results\n",
    "def stream_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "906f4872-7489-4e4e-8928-cff007faad70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_gpt,\n",
    "    inputs=[gr.Textbox(label=\"Your Message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35ff55df-0ff5-465a-b8c3-6e9f503b0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google model with streaming in Markdown\n",
    "gemini_via_openai_client = OpenAI(\n",
    "    api_key=google_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "def stream_google(prompt):\n",
    "    messages=[{\"role\": \"system\", \"content\": system_message},\n",
    "              {\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    stream_result = gemini_via_openai_client.chat.completions.create(\n",
    "        model='gemini-2.0-flash',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    result=\"\"\n",
    "    for chunk in stream_result:\n",
    "        result+= chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fd14ee9-0a28-4567-bd3e-77ef0ab6cb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_google,\n",
    "    inputs=[gr.Textbox(label=\"Your Message:\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2bc2af5-f056-4e14-9fdb-aba9d7179cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to select model for response\n",
    "def stream_model(prompt, model):\n",
    "    if model == 'GPT':\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model == 'Google':\n",
    "        result = stream_google(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6551f73c-1e7f-4553-a618-8ca7f674964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7873\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_model,\n",
    "    inputs=[gr.Textbox(label=\"Your Message:\"),\n",
    "            gr.Dropdown(['GPT', 'Google'], label=\"Select the model\", value='GPT')],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38560d2e-575e-4f82-b422-e56fb86f4a05",
   "metadata": {},
   "source": [
    "## Building a company brochure generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "792dca43-2533-43d5-b914-b2df783d7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent the webpage scraper\n",
    "\n",
    "# Some websites need you to use proper headers when fetching their content:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scrapped with hyperlinks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url: str):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No Title Found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body(['script', 'style', 'img', 'input']):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator='\\n', strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get(\"href\") for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self) -> str:\n",
    "        return f\"Webpage title: {self.title}\\nWebpage Content:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9f85771-7a52-4e72-b19d-f19c65d998b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brouchure about the company,such as links to an About page, or Company page, or Careers/Jobs pages.\n",
      "You should responde is JSON as in this example:\n",
      "{\n",
      "    links=[\n",
      "        {\"type\": \"about_page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers_page\", \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Single shot prompting for better results\n",
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brouchure about the company,\\\n",
    "such as links to an About page, or Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should responde is JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    links=[\n",
    "        {\"type\": \"about_page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers_page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# printing the prompt\n",
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7778563f-d3fe-456c-8f22-c3b7e9e6b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to embed the website to the prompt\n",
    "def get_user_link_prompt(website: Website) -> str:\n",
    "    user_prompt = f\"Here is a list of list of links on the website of {website.url}\\n\"\n",
    "    user_prompt += \"Please decide which of these are relevant web links for a broucher about the company, respond with the full http URL in JSON format. \\\n",
    "Do not include Terms and Services or Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c575447-08c7-47df-80e8-01cefb8bd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch the hyperlinks from a website with llm\n",
    "def get_links(url: str):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_user_link_prompt(website)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4387c8ac-a017-4cb1-b834-21371c81024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assemble all the details into a single prompt before sending this to LLM Model\n",
    "def get_all_details(url: str):\n",
    "    result = \"Landing Page:\\n\"\n",
    "\n",
    "    links = get_links(url)\n",
    "    for link in links['links']:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(url).get_contents()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d56aefa0-cf0e-463f-af1e-6157f8db953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt to create the company brochure\n",
    "system_message = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\"\n",
    "\n",
    "def get_brochure_user_prompt(company_name: str, url: str) -> str: \n",
    "    user_prompt = f\"You are looking at a company called: {company_name}.\\n\"\n",
    "    user_prompt += \"Here are the contents of its landing page and other relevant pages; \"\n",
    "    user_prompt += \"Use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "323535b7-179d-48a5-90c2-a2a1a27d01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate company brochure with LLM model\n",
    "def create_brochure(company_name: str, url: str):\n",
    "    response = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ]\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(str(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "daf20b74-5e0d-4df1-87a7-4f6f139a6743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Brochure\n",
       "\n",
       "---\n",
       "\n",
       "## **About Us**\n",
       "Hugging Face is the vibrant AI community dedicated to building the future of machine learning. Our platform fosters collaboration among AI specialists by providing tools for sharing models, datasets, and applications.\n",
       "\n",
       "---\n",
       "\n",
       "## **Our Offerings**\n",
       "- **Models**: Access a vast library of over **1 million models** to accelerate your projects.\n",
       "- **Datasets**: With **250k+ datasets**, we simplify the process of finding and utilizing quality data.\n",
       "- **Spaces**: Create and share applications in various modalities including text, image, and audio.\n",
       "- **Services**: Explore our **Compute solutions** starting at $0.60/hour for GPU and **Enterprise solutions** from $20/user/month.\n",
       "\n",
       "---\n",
       "\n",
       "## **Trending Models This Week**\n",
       "1. **nvidia/parakeet-tdt-0.6b-v2** - 42.1k Views\n",
       "2. **nari-labs/Dia-1.6B** - 144k Views\n",
       "3. **ACE-Step/ACE-Step-v1-3.5B** - 262 Views\n",
       "\n",
       "Explore more on our platform!\n",
       "\n",
       "---\n",
       "\n",
       "## **Collaborate and Innovate**\n",
       "Our open-source tools encourage community contributions, enabling the development of:\n",
       "- **Transformers**: 144,075 implementations across multiple frameworks.\n",
       "- **Diffusers**: 28,903 cutting-edge models for generating various media.\n",
       "- **Safetensors**: A secure method for handling neural network weights.\n",
       "\n",
       "---\n",
       "\n",
       "## **Join Our Community**\n",
       "With more than **50,000 organizations** including names like Google, Microsoft, and Amazon leveraging our platform, Hugging Face is at the forefront of AI innovation.\n",
       "\n",
       "### Prospective Clients\n",
       "Empower your teams with advanced tools, enterprise-grade security, and dedicated support.\n",
       "\n",
       "### Investors\n",
       "Become part of a rapidly growing community reshaping AI with the latest tools and technologies.\n",
       "\n",
       "### Recruits\n",
       "Join us and collaborate with top minds in the industry to push the boundaries of what AI can achieve.\n",
       "\n",
       "---\n",
       "\n",
       "## **Get Involved**\n",
       "- **Sign Up**: Create your account today and start collaborating.\n",
       "- **Explore**: Dive deep into **1 million models** and **400k applications**.\n",
       "- **Connect**: Follow us on [GitHub](https://github.com), [Twitter](https://twitter.com), [LinkedIn](https://www.linkedin.com), and [Discord](https://discord.com) for updates.\n",
       "\n",
       "---\n",
       "\n",
       "### **Visit Us Today**\n",
       "For more information, explore our full suite of services at [Hugging Face](https://huggingface.co/).\n",
       "\n",
       "---\n",
       "\n",
       "Building The Future of AI, Together."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure('HuggingFace', 'https://huggingface.co')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69889c2d-7538-4e4c-b53a-17b9f34ead89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create brochure with different LLM models with streaming\n",
    "def brochure_stream_model(company_name: str, url: str, model: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}]\n",
    "\n",
    "    if model == \"GPT\":\n",
    "        stream_response = openai.chat.completions.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=messages,\n",
    "            stream=True)\n",
    "\n",
    "    elif model == \"Google\":\n",
    "        stream_response = gemini_via_openai_client.chat.completions.create(\n",
    "            model='gemini-2.0-flash',\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Model\")\n",
    "\n",
    "    result = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream_response:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        \n",
    "        # Update the displayed Markdown content with the latest response\n",
    "        update_display(Markdown(result), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36fa50a1-db75-4ed1-9828-7ef100bff99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Brochure\n",
       "\n",
       "Welcome to **Hugging Face** – the AI community building the future!\n",
       "\n",
       "## Who We Are\n",
       "Hugging Face is a collaborative platform designed for the machine learning community to create, discover, and share models, datasets, and applications. With us, you're not just a user; you're part of a thriving community of innovators and creators.\n",
       "\n",
       "## Our Offerings\n",
       "\n",
       "### **Models**\n",
       "Explore over **1 million+ models** across various domains including:\n",
       "- **NLP**\n",
       "- **Computer Vision**\n",
       "- **Audio Processing**\n",
       "\n",
       "### **Datasets**\n",
       "Access an extensive library of **250,000+ datasets** tailored for a myriad of machine learning tasks, enhancing your research and development processes.\n",
       "\n",
       "### **Spaces**\n",
       "Join **400,000+ applications** hosted on our platform, featuring tools like:\n",
       "- **DeepSite** - Generate applications effortlessly.\n",
       "- **ICEdit** - Universal image editing tool.\n",
       "\n",
       "### **Compute Solutions**\n",
       "We provide paid **Compute Solutions** starting at **$0.60/hour** for GPU deployment, designed to empower enterprises and users to move faster and make an impact.\n",
       "\n",
       "### **Enterprise Solutions**\n",
       "For organizations, we offer enterprise-grade tools with:\n",
       "- Security features\n",
       "- Dedicated support\n",
       "- Custom access controls\n",
       "Starting at **$20/user/month**\n",
       "\n",
       "## Why Choose Us?\n",
       "- **Open Source Community:** We are committed to building the foundation of machine learning tools together with our users – including popular tools such as **Transformers**, **Diffusers**, and **Tokenizers**.\n",
       "- **Robust Support:** Join over **50,000 organizations** including tech giants like Google, Microsoft, and Amazon in leveraging our powerful tools.\n",
       "\n",
       "## Join Us!\n",
       "Explore the possibilities of AI with Hugging Face. \n",
       "- **Sign Up Today** and start contributing to revolutionary projects.\n",
       "- Discover our offerings through our [Website](https://huggingface.co).\n",
       "\n",
       "### Connect With Us\n",
       "- **GitHub:** [Hugging Face GitHub](https://github.com/HuggingFace)\n",
       "- **Twitter:** [@huggingface](https://twitter.com/huggingface)\n",
       "- **LinkedIn:** [Hugging Face on LinkedIn](https://www.linkedin.com/company/huggingface)\n",
       "- **Join our Discord community** to collaborate and learn from peers.\n",
       "\n",
       "---\n",
       "\n",
       "Together, let’s build the AI culture of the future!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brochure_stream_model('HuggingFace', 'https://huggingface.co', 'GPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "91d6ac31-79b0-4a36-8bc9-86999ff87aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brochure_stream_model(company_name: str, url: str, model: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}]\n",
    "\n",
    "    if model == \"GPT\":\n",
    "        stream_response = openai.chat.completions.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=messages,\n",
    "            stream=True)\n",
    "\n",
    "    elif model == \"Google\":\n",
    "        stream_response = gemini_via_openai_client.chat.completions.create(\n",
    "            model='gemini-2.0-flash',\n",
    "            messages=messages,\n",
    "            stream=True\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Model\")\n",
    "\n",
    "    result = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream_response:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        \n",
    "        # Update the displayed Markdown content with the latest response\n",
    "        # update_display(Markdown(result), display_id=display_handle.display_id) # uncomment this to run on local notebook\n",
    "        yield result  # This will stream the result to Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cf074a41-da90-4672-94d9-cb2ab4ffa099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7879\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7879/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradio Interface to generate company brochure with different LLM models\n",
    "view = gr.Interface(\n",
    "    fn=brochure_stream_model,\n",
    "    inputs=[\n",
    "        gr.Textbox(label='Company Name:'),\n",
    "        gr.Textbox(label='URL'),\n",
    "        gr.Dropdown([\"GPT\", \"Google\"], label=\"Select the model\", value=\"GPT\")\n",
    "    ],\n",
    "    outputs=gr.Markdown(label=\"Response:\"),\n",
    "    flagging_mode=\"never\",\n",
    ")\n",
    "\n",
    "view.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-llm-practical",
   "language": "python",
   "name": ".venv-llm-practical"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
